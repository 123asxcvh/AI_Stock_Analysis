#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
ç®€åŒ–å¸‚åœºAIåˆ†æå™¨
åªä¿ç•™æ ¸å¿ƒåŠŸèƒ½
"""

import sys
from pathlib import Path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

import pandas as pd
import asyncio
import aiofiles
import time
from typing import Dict, Any, List
from datetime import datetime

from config import (
    config, MODEL_NAME, MAX_CONCURRENCY,
    AsyncAIAnalyzerBase, DataProcessor
)
from src.ai_analysis.prompts.prompt_manager import PromptManager


def get_market_default_config():
    """è·å–å¸‚åœºåˆ†æçš„é»˜è®¤é…ç½®å‚æ•°"""
    # ä»é…ç½®ç³»ç»Ÿè·å–å¸‚åœºåˆ†æç±»å‹
    supported_market_analysis_types = config.supported_market_analysis_types
    return (
        config.market_data_dir,
        config.ai_reports_dir,
        supported_market_analysis_types,
        MODEL_NAME
    )

def run_main(main_func):
    if sys.platform == "win32":
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    try:
        asyncio.run(main_func())
    except KeyboardInterrupt:
        print("ç”¨æˆ·ä¸­æ–­æ“ä½œ")

class AsyncMarketAIAnalyzer(AsyncAIAnalyzerBase):
    """ç®€åŒ–å¼‚æ­¥å¸‚åœºAIåˆ†æå™¨"""

    # æ•°æ®é‡‡æ ·é™åˆ¶é…ç½®
    DATA_LIMITS = {
        "fund_flow_concept": 100,      # æ¦‚å¿µæ¿å—èµ„é‡‘æµå‘
        "fund_flow_industry": 50,      # è¡Œä¸šèµ„é‡‘æµå‘
        "fund_flow_individual": 50,    # ä¸ªè‚¡èµ„é‡‘æµå‘
        "zt_pool": 50,                 # æ¶¨åœè‚¡ç¥¨æ± 
        "news_main_cx": 30,            # è´¢ç»æ–°é—»ï¼ˆæœ€è¿‘1ä¸ªæœˆï¼‰
        "market_activity_legu": 12     # å¸‚åœºæ´»è·ƒåº¦ï¼ˆå…¨éƒ¨æ•°æ®ï¼‰
    }

    # æ™ºèƒ½é‡‡æ ·é…ç½® - å¯¹fund_flow_conceptå’Œfund_flow_individualè¿›è¡Œé‡‡æ ·
    SAMPLING_CONFIG = {
        "fund_flow_concept": {"first_percent": 0.7, "last_percent": 0.3, "min_rows": 70},      # æ¦‚å¿µæ¿å—èµ„é‡‘æµå‘éœ€è¦é‡‡æ ·ï¼Œ100è¡Œ
        "fund_flow_individual": {"first_percent": 0.7, "last_percent": 0.3, "min_rows": 35},  # ä¸ªè‚¡èµ„é‡‘æµå‘éœ€è¦é‡‡æ ·ï¼Œ50è¡Œ
        "news_main_cx": {"first_percent": 1.0, "last_percent": 0.0, "min_rows": 30},          # æ–°é—»æŒ‰æ—¶é—´é¡ºåºå–æœ€æ–°
        "market_activity_legu": {"first_percent": 1.0, "last_percent": 0.0, "min_rows": 12}    # å¸‚åœºæ´»è·ƒåº¦å–å…¨éƒ¨
    }

    def __init__(self, model_name: str = None):
        super().__init__(model_name)
        self.data_dir = config.data_dir / "cleaned_market_data"
        config.ensure_dir(self.data_dir)
        # ç«‹å³åˆå§‹åŒ–prompt_managerï¼Œä¸ä¾èµ–å¼‚æ­¥ä¸Šä¸‹æ–‡
        from src.ai_analysis.prompts.prompt_manager import PromptManager
        self.prompt_manager = PromptManager()

    def _smart_sample_data(self, df: pd.DataFrame, analysis_type: str) -> pd.DataFrame:
        """
        æ™ºèƒ½æ•°æ®é‡‡æ ·ç­–ç•¥
        - å¯¹äºå¤§å®¹é‡æ•°æ®ï¼Œé‡‡ç”¨å‰N% + åM%çš„ç­–ç•¥
        - æ—¢ä¿è¯åŒ…å«æœ€æ–°æ•°æ®ï¼Œåˆä¿ç•™å†å²æ•°æ®è¿›è¡Œå¯¹æ¯”

        Args:
            df: åŸå§‹æ•°æ®DataFrame
            analysis_type: åˆ†æç±»å‹

        Returns:
            é‡‡æ ·åçš„DataFrame
        """
        total_rows = len(df)
        max_limit = self.DATA_LIMITS.get(analysis_type, 100)

        # å¦‚æœæ•°æ®é‡ä¸è¶…è¿‡é™åˆ¶ï¼Œç›´æ¥è¿”å›
        if total_rows <= max_limit:
            return df

        # è·å–é‡‡æ ·é…ç½®
        sampling_config = self.SAMPLING_CONFIG.get(analysis_type,
                                                 {"first_percent": 0.6, "last_percent": 0.4, "min_rows": 30})

        first_percent = sampling_config["first_percent"]
        last_percent = sampling_config["last_percent"]
        min_rows = sampling_config["min_rows"]

        # è®¡ç®—é‡‡æ ·è¡Œæ•°
        first_rows = int(max_limit * first_percent)
        last_rows = max_limit - first_rows

        # ç¡®ä¿è‡³å°‘æœ‰æœ€å°è¡Œæ•°
        if first_rows < min_rows:
            first_rows = min_rows
            last_rows = max_limit - first_rows

        # é‡‡æ ·æ•°æ®ï¼šå‰Nè¡Œ + åMè¡Œ
        df_first = df.head(first_rows)
        df_last = df.tail(last_rows)

        # åˆå¹¶æ•°æ®
        df_sampled = pd.concat([df_first, df_last], ignore_index=True)

        print(f"ğŸ“Š {analysis_type}: æ™ºèƒ½é‡‡æ ·å®Œæˆ - åŸå§‹{total_rows}è¡Œ â†’ é‡‡æ ·{len(df_sampled)}è¡Œ (å‰{first_rows}+å{last_rows}è¡Œ)")

        return df_sampled

    async def process_market_analysis(self, analysis_types: List[str], output_dir: str) -> Dict[str, Any]:
        """å¤„ç†æ‰€æœ‰å¸‚åœºåˆ†æç±»å‹ - ä½¿ç”¨ä¿¡å·é‡æ§åˆ¶å¹¶å‘"""
        # åˆ›å»ºè¾“å‡ºç›®å½•
        market_reports_dir = Path(output_dir)
        market_reports_dir.mkdir(parents=True, exist_ok=True)

        # åˆ›å»ºç»“æœè·Ÿè¸ª
        completed_tasks = {"successful": 0, "failed": 0}
        
        # ä½¿ç”¨ä¿¡å·é‡æ§åˆ¶å¹¶å‘æ•°ï¼ˆä»é…ç½®è·å–æœ€å¤§å¹¶å‘æ•°ï¼‰
        semaphore = asyncio.Semaphore(MAX_CONCURRENCY)

        async def process_analysis_with_semaphore(analysis_type: str):
            """å¼‚æ­¥å¤„ç†å•ä¸ªåˆ†æç±»å‹ï¼Œä½¿ç”¨ä¿¡å·é‡æ§åˆ¶å¹¶å‘"""
            async with semaphore:
                try:
                    # ä»AIé…ç½®ç®¡ç†å™¨è·å–æ–‡ä»¶æ˜ å°„
                    market_analysis_file_mapping = config.market_analysis_file_mapping
                    required_files = market_analysis_file_mapping[analysis_type]

                    # è¯»å–æ–‡ä»¶æ•°æ®ï¼ˆä½¿ç”¨æ™ºèƒ½é‡‡æ ·ï¼‰
                    file_data = {}
                    for filename in required_files:
                        df = await DataProcessor.read_csv_file_async(str(self.data_dir / filename))
                        if df is not None:
                            # åº”ç”¨æ™ºèƒ½æ•°æ®é‡‡æ ·
                            original_rows = len(df)
                            df_sampled = self._smart_sample_data(df, analysis_type)
                            print(f"ğŸ“Š {analysis_type} - {filename}: åŸå§‹æ•°æ® {original_rows} è¡Œ â†’ é‡‡æ ·å {len(df_sampled)} è¡Œ")
                            file_data[filename] = df_sampled

                    # æ„å»ºæ•°æ®æ‘˜è¦
                    if not file_data:
                        data_summary = f"æš‚æ— {analysis_type}çš„å…·ä½“æ•°æ®ï¼Œè¯·åŸºäºå¸‚åœºå¸¸è¯†å’Œä¸“ä¸šçŸ¥è¯†è¿›è¡Œåˆ†æã€‚"
                        print(f"âš ï¸  {analysis_type} æœªè¯»å–åˆ°æ•°æ®æ–‡ä»¶")
                        return True
                    
                    summary_parts = [f"=== {analysis_type.upper()} å¸‚åœºæ•°æ®åˆ†æ ==="]

                    # æ·»åŠ é‡‡æ ·è¯´æ˜
                    sampling_config = self.SAMPLING_CONFIG.get(analysis_type,
                                                             {"first_percent": 0.6, "last_percent": 0.4})
                    first_percent = int(sampling_config["first_percent"] * 100)
                    last_percent = int(sampling_config["last_percent"] * 100)
                    summary_parts.append(f"**æ•°æ®è¯´æ˜**: å·²åº”ç”¨æ™ºèƒ½é‡‡æ ·ç­–ç•¥ï¼Œé€‰å–å‰{first_percent}% + å{last_percent}%çš„æ•°æ®ä»¥å…¼é¡¾æœ€æ–°è¶‹åŠ¿å’Œå†å²å¯¹æ¯”")
                    summary_parts.append("")

                    total_rows = 0
                    for filename, df in file_data.items():
                        summary_parts.append(f"=== {filename} ===")
                        total_rows += len(df)

                        # æ•°æ®å·²ç»è¿‡æ™ºèƒ½é‡‡æ ·
                        summary_parts.append(f"é‡‡æ ·æ•°æ®è¡Œæ•°: {len(df)}")
                        rows_data = df.to_dict('records')
                        for row in rows_data:
                            row_info = " | ".join([f"{col}: {val}" for col, val in row.items() if pd.notna(val)])
                            summary_parts.append(row_info)
                        summary_parts.append("")
                    data_summary = "\n".join(summary_parts)
                    print(f"âœ… {analysis_type} æ•°æ®å‡†å¤‡å®Œæˆï¼Œæ‘˜è¦é•¿åº¦: {len(data_summary)} å­—ç¬¦ï¼Œé‡‡æ ·æ•°æ®æ€»è¡Œæ•°: {total_rows}ï¼Œæ–‡ä»¶æ•°: {len(file_data)}")

                    # è°ƒç”¨AI APIè¿›è¡Œåˆ†æ
                    prompt_config = self.prompt_manager.get_market_prompt(analysis_type)
                    system_content = self.prompt_manager.get_market_system_prompt(
                        prompt_config.get("market_system_prompt", "market_strategist")
                    )
                    user_prompt = prompt_config.get("market_user_prompt", "è¯·å¯¹ä»¥ä¸‹å¸‚åœºæ•°æ®è¿›è¡Œä¸“ä¸šåˆ†æã€‚")
                    
                    messages = [
                        {"role": "system", "content": system_content},
                        {"role": "user", "content": f"{user_prompt}\n\n**æ•°æ®è¾“å…¥ï¼š**\n{data_summary}"}
                    ]
                    
                    print(f"ğŸ”„ {analysis_type} æ­£åœ¨è°ƒç”¨AI API...")
                    analysis_result = await self._call_ai_api_with_retry(messages)
                    
                    # ç»Ÿä¸€å¤„ç†APIè°ƒç”¨ç»“æœ
                    success, processed_result = self._process_api_result(analysis_result, analysis_type)
                    if success:
                        completed_tasks["successful"] += 1
                    else:
                        completed_tasks["failed"] += 1

                    # ä¿å­˜ç»“æœ
                    output_path = market_reports_dir / f"{analysis_type}.md"
                    await self._write_analysis_result(output_path, processed_result)
                    
                    print(f"âœ… å¸‚åœºåˆ†æ {analysis_type} å¤„ç†å®Œæˆ")
                    return True
                except Exception as e:
                    print(f"âŒ å¸‚åœºåˆ†æ {analysis_type} å¼‚å¸¸: {e}")
                    import traceback
                    traceback.print_exc()
                    completed_tasks["failed"] += 1

                    # ä¿å­˜é”™è¯¯ä¿¡æ¯ï¼ˆé™é»˜å¤±è´¥ï¼‰
                    error_content = f"âŒ å¸‚åœºåˆ†æ {analysis_type} å¼‚å¸¸: {str(e)}\n\nè¯¦ç»†é”™è¯¯:\n{traceback.format_exc()}"
                    await self._write_analysis_result_safe(market_reports_dir / f"{analysis_type}.md", error_content)
                    return True

        # åˆ›å»ºå¹¶å‘ä»»åŠ¡ï¼ˆä½¿ç”¨ä¿¡å·é‡æ§åˆ¶ï¼Œä¸å†ä½¿ç”¨å›ºå®šå»¶è¿Ÿï¼‰
        tasks = [
            asyncio.create_task(process_analysis_with_semaphore(analysis_type))
            for analysis_type in analysis_types
        ]

        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        await asyncio.gather(*tasks, return_exceptions=True)

        # ç»Ÿè®¡ç»“æœ
        successful_analyses = completed_tasks["successful"]
        failed_analyses = completed_tasks["failed"]
        
        return {
            "success": True,
            "successful_analyses": successful_analyses,
            "failed_analyses": failed_analyses,
            "total_analyses": len(analysis_types),
            "output_dir": str(market_reports_dir)
        }

    async def _write_analysis_result(self, output_path: str, content: str):
        """å¼‚æ­¥å†™å…¥åˆ†æç»“æœåˆ°æ–‡ä»¶"""
        async with aiofiles.open(output_path, 'w', encoding='utf-8') as f:
            await f.write(content)

    async def _write_analysis_result_safe(self, output_path: str, content: str):
        """å®‰å…¨å†™å…¥åˆ†æç»“æœåˆ°æ–‡ä»¶ï¼ˆé™é»˜å¤±è´¥ï¼‰"""
        try:
            await self._write_analysis_result(output_path, content)
        except Exception:
            pass

    def _process_api_result(self, analysis_result: str, analysis_type: str) -> tuple[bool, str]:
        """å¤„ç†APIè°ƒç”¨ç»“æœï¼Œè¿”å›(æˆåŠŸçŠ¶æ€, å¤„ç†åç»“æœ)"""
        if analysis_result:
            print(f"âœ… {analysis_type} APIè°ƒç”¨æˆåŠŸ")
            return True, analysis_result
        else:
            error_result = f"âŒ {analysis_type} AIåˆ†æå¤±è´¥ - APIè¿”å›ç©ºç»“æœ"
            print(f"âŒ {analysis_type} APIè°ƒç”¨è¿”å›ç©ºç»“æœ")
            return False, error_result

async def main():
    """ä¸»å¼‚æ­¥å‡½æ•°"""
    data_dir, output_dir, analysis_types, model_name = get_market_default_config()
    
    start_time = time.time()
    
    print(f"ğŸ¤– å¯åŠ¨å¸‚åœºAIåˆ†æ...")
    print(f"ğŸ“‚ æ•°æ®ç›®å½•: {data_dir}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    print(f"ğŸ”§ åˆ†æç±»å‹: {', '.join(analysis_types)}")
    print("=" * 50)
    
    async with AsyncMarketAIAnalyzer(model_name) as analyzer:
        result = await analyzer.process_market_analysis(analysis_types, str(output_dir))
        
        total_time = time.time() - start_time
        
        print("\n" + "=" * 50)
        print("ğŸ“ˆ å¸‚åœºAIåˆ†ææ€»ç»“")
        print(f"   æ€»åˆ†ææ•°: {result['total_analyses']}")
        print(f"   æˆåŠŸåˆ†æ: {result['successful_analyses']}")
        print(f"   å¤±è´¥åˆ†æ: {result['failed_analyses']}")
        print(f"   æˆåŠŸç‡: {result['successful_analyses'] / result['total_analyses'] * 100:.1f}%")
        print(f"   æ€»è€—æ—¶: {total_time:.2f} ç§’")
        print(f"   æŠ¥å‘Šç›®å½•: {result['output_dir']}")

if __name__ == "__main__":
    run_main(main)